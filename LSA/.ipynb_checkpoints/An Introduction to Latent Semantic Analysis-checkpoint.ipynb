{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Latent Semantic Analysis\n",
    "\n",
    "<hr>\n",
    "\n",
    "This python notebook demonstrates how to perform Latent Semantic Analysis (LSA) on a corpus of text. There are a couple of other tutorials (see here and here) that this example builds upon and I hope the python along with the theory will help you out in using this technique for your own research.\n",
    "\n",
    "In this example, we are going to analyse a book of abstracts from a conference to determine the similarity between the conference papers that are going to be presented. This information could be useful to conference organisers wishing to group similar research together and/or as part of a search tool for the attendees to find similar work that might be of interest.\n",
    "\n",
    "We will be treating each abstract as a list of words. From this, will form a $N \\times M$ matrix with the column vectors representing the abstracts (and thus, paper), and the row vectors representing the words. There are four key steps to the analysis and we will be stepping through each one with the code and output from each stage being explained. The stages are:\n",
    "\n",
    "* Generating a list of words from the abstracts\n",
    "* Creating the word-abstract matrix\n",
    "* Applying the Term Frequency - Inverse Document Frequency (TF-IDF) Weighting Scheme\n",
    "* Using Singular Value Decomposition (SVD) to derive the underlying concepts across the documents\n",
    "\n",
    "Before we get underway, we need to first import all the packages that we will be using. These are:\n",
    "\n",
    "* Numpy - for handling matrices and the svd function\n",
    "* Matplotlib - for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A line of code that jupyter notebook uses to plot the images inline with the code and text\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing the packages that we need\n",
    "import numpy as np # For matrices and SVD function\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "import json # To read in JSON data\n",
    "from pprint import pprint # To pretty print text output to console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a list of words\n",
    "\n",
    "Before we can form the $N \\times M$ matrix of words against abstracts, we need to decide on the list of words that we will be using to compare the abstracts. The first thing we need to do is load up the dataset and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data from the file\n",
    "#with open('', 'r') as data_file:\n",
    "#    data = json.load(data_file)\n",
    "#pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Improvements\n",
    "\n",
    "* Considering tri-grams & bi-grams\n",
    "* Stemming\n",
    "* Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
